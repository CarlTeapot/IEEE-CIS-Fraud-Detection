# IEEE-CIS Fraud Detection


IEEE-CIS Fraud Detection

ამ დავალების მიზანია დავატრენინგოთ მოდელი, რომელიც ეფექტურად ამოიცნობს თაღლითურ ტრანზაქციებს

პირველ რიგში დავაჯოინე train_transactions და train_identity მონაცემები ტრანზაქციის ID-ს მიხედვით და დაჯოინებულ dataset-ზე ვმუშაობდი, თუმცა საბოლოოდ გადავწყვიტე train_identity დატასეტის უგულებელყოფა. 

გამოვიყენე undersampling -ის ტექნიკა. შედეგად მივიღე dataset, სადაც მონაცემების isFraud მნიშვნელობების შეფარდება 3:1 იყო (0,1)
შედეგად, მონაცემები გახდა უფრო დაბალანსებული და მოდელმა უკეთ ისწავლა ორივე კლასის განასხვავება.

მონაცემები სტანდარტულად დავყავით 80% დასატრენინგებლად და 20% დასატესტად. 

შევქმენი კლასი ColumnDropper(), რომელიც ფილტრავდა ისეთ სვეტებს, რომლებშიც nan-ების პროცენტული განაწილება განსაზღვრულ threshold -ზე მაღალი იყო, random_search-ში კი ბევრ სხვადასხვა threshold - ზე ვცდილობდი მოდელის დატრენინგებას. 

გამოვიყენე nan - ების შევსების სხვადასხვა ტექნიკები -> რიცხვით სვეტებში nan-ების საშუალოებით, მედიანებითა და განსაზღვრული მუდმივი მნიშვნელობებით ჩანაცვლება, ხოლო კატეგორიულ სვეტებში ყველაზე ხშირი მნიშვნელობით ჩანაცვლება. 

კატეგორიული სვეტების რიცხვით სვეტებში გარდასაქმნელად გამოვიყენე ბევრი სხვადასხვა მიდგომა: 
OneHotEncoder, TargetEncoder, BinaryEncoder, CountEncoder 

რიცხვითი ცვლადების [0,1] ინტერვალში გარდასაქმნელად გამოვიყენე ბევრი მიდგომა:
StandardScaler, MinMaxScaler, RobustScaler

მოდელები რომლებიც გამოვიყენე: Random Forest, Logistic Regression, Perceptron, XG_Boost, Gradient_Boost, Ada_boost
გამოვიყენე cross ვალიდაცია მნიშვნელობით -3, რომელიც შემდგომში kfold cross ვალიდაციით შევცვალე. 

grid_search -ის ნაცვლად გამოვიყენე random_search, რადგანაც grid_search-ს ძალიან დიდი ხანი სჭირდებოდა. 

პირველი მოდელის დატრენინგებისას, რომელშიც Random Forest გამოვიყენე, საკმაოდ საინტერესო შედეგი მივიღე:
Training ROC-AUC: 1.0000
Test ROC-AUC:     0.9406

ამ შედეგმა დამაეჭვა, რომ ჩვენი მოდელი overfitted იყო. მალევე ვიპოვე პრობლემა: random forest -ის პარამეტრებში არ მქონდა მაქსიმალური სიღრძე და ფოთლების რაოდენობა შეზღუდული, რაც იწვევდა რომ მოდელი ზედმეტად flexible იყო. 

'model__n_estimators': randint(50, 150),  
'model__max_depth': randint(5, 10),        
'model__max_features': ['sqrt', 'log2'],
'model__min_samples_split': randint(10, 20),  
'model__min_samples_leaf': randint(5, 10),  
'model__max_leaf_nodes': randint(20, 100)   

ამ პარამეტრების შეცვლამ შემდეგი შედეგი მომცა:

Training ROC-AUC: 0.8707
Test ROC-AUC:     0.8725

ამ პარამეტრებმა გვიშველა overfitting-ისგან test_set ზე სიზუსტის დაკარგვის ფასად (აქ test_set ში train.csv-დან დასატესტად გამოყოფილი ნაწილი)

საინტერესო აღსაღნიშნია, რომ cross validation-ის (რომელიც 3-ზე მეყენა) kfold cv- თი ჩანაცვლებით (5 folds) დიდი ვერაფერი შეცვალა. 

feature selection -ში ვცადე კიდევ ერთი მიდგომა. თავიდან მოდელებს ვქმნიდი train_transaction და train_identity dataset-ების გაერთიანებით (transactionID-ს მიხედვით). საინტერესოა, რომ train_identity -ს უგულებელყოფით არაფერი არ შეიცვალა, ამიტომ ყველა მოდელში მხოლოდ train_transaction -ს ვიყენებ დასატრენინგებლად.  

Random Forest მოდელის შედეგი: 0.773241


Logistic Regression დატრენინგება ძალიან ნელი გამოდგა, ამიტომ მომიწია k-fold -ის ჩვეულებრივი CV-თი ჩანაცვლება. მომიწია ბევრი cleaning და feature engineering ტექნიკის ამოღება random_search-იდან. გამოვიყენე "liblinear" Solver, მიუხედავად იმისა, რომ "saga" solver დიდი ზომის დატასეტებზე უფრო სწრაფია.  მიუხედავად იმისა, რომ ეს მოდელი უფრო ნაკლებ ვარიანტს განიხილავდა, მაინც  უკეთესი შედეგი დადო, ვიდრე random forest-მა.

Logistic Regression შედეგები:

Training set: 0.844
Test set: 0.845 
Submission: 0.779931

ლოჯისტიკური რეგრესიის მოდელი ბევრად უკეთეს შედეგსაც დადებს, თუმცა ამას ბევრად მეტი დრო დასჭირდებოდა


Perceptron შედეგები:

Training set: 0.845
Test set: 0.844 
Submission: 0.669446

პერცეპტრონის ცუდი შედეგი ლოგიკურია, რადგან პერცეპტრონი შედარებით პრიმიტიული მოდელია, რომელსაც უჭირს კომპლექსური, არაწრფივი დამოკიდებულებების პოვნა


XGBoost მოდელის შედეგები:

Test set: 0.954
Training set: 0.987
Submission: 0.825210

Hist Gradient Boosting მოდელის შედეგები:

Training Set: 0.952
Test Set:     0.933
Submission: 0.820372

